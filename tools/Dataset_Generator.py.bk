from __future__ import print_function

import time
import warnings
import numpy as np
import glob
import os
import math
import sys

from keras.utils import to_categorical
from random import shuffle, randint
from scipy.misc import imread
import skimage.transform
from utils import compute_mean_std, load_img
from random import randint
from utils import shuffle


###################
#import skimage.io as io
#from skimage.color import rgb2gray, gray2rgb
#import skimage.transform
import numpy as np
#from numpy import ma
#from numpy.linalg import inv
import scipy.ndimage as ndi
#from six.moves import range
import SimpleITK as sitk
#import threading

#from keras import backend as K

#from tools.save_images import save_img2
###################

class Dataset_Generator(object):
    def __init__(self, cf, dataset_images_path, n_classes=2, batch_size=5, resize_image=(224, 224), shuffle_dataset=False, 
                 shuffle_batch=False, apply_augmentation=False, sampling_score=None, data_path='data', data_path2=None, mode='train'):

        self.dataset_images_path = dataset_images_path
        self.batch_size = batch_size
        self.n_classes = n_classes
        self.shuffle_dataset = shuffle_dataset
        self.shuffle_batch = shuffle_batch
        self.resize_image = resize_image
        self.rescale = cf.norm_rescale
        self.featurewise_center = cf.norm_featurewise_center
        self.featurewise_std_normalization = cf.norm_featurewise_std_normalization
        self.mode=mode

        ###################
        self.rotation_range = cf.da_rotation_range
        self.height_shift_range = cf.da_height_shift_range
        self.width_shift_range = cf.da_width_shift_range
        self.shear_range = cf.da_shear_range
        self.zoom_range = cf.da_zoom_range

        self.channel_shift_range = cf.da_channel_shift_range
        self.fill_mode = cf.da_fill_mode
        self.horizontal_flip = cf.da_horizontal_flip
        self.vertical_flip = cf.da_vertical_flip
        self.spline_warp = cf.da_spline_warp

        self.warp_sigma = cf.da_warp_sigma
        self.warp_grid_size = cf.da_warp_grid_size
        self.cval = cf.da_cval

        self.crop_size = cf.crop_size_image
        self.save_to_dir = cf.da_save_to_dir
        ###################

        self.imageNet = cf.load_imageNet

        ##############

        self.history_batch_fnames = np.array([''])
        self.history_batch_labels = np.array([], dtype=np.int32)

        self.apply_augmentation = apply_augmentation
        self.sampling_score = sampling_score

        if mode not in {'train', 'validation', 'test'}:
            raise ValueError('Invalid mode: ', mode, '; expected \'train\', \'validation\' or \'test\'')

        # Load training set
        print('\n > Reading: ' + mode + ' set...')
        print('   Data path: ' + data_path)
        print('   Dataset images path: ' + dataset_images_path)


        # Load Neop: X_train/validation/test_neop.npy, y_train/validation/test_neop.npy
        self.X_neop = np.load(data_path + '_X_' + mode + '_neop.npy')
        self.y_neop = np.load(data_path + '_y_' + mode + '_neop.npy')

        # Load NOneo: X_train/validation/test_noneo.npy, y_train/validation/test_noneo.npy
        self.X_noneo = np.load(data_path + '_X_' + mode + '_noneo.npy')
        self.y_noneo = np.load(data_path + '_y_' + mode + '_noneo.npy')

        # We have only 2 classes
        # noneo = class 0
        # neo   = class 1
        self.y_noneo_class = np.zeros((len(self.y_noneo),), dtype=np.int32)
        self.y_neop_class = np.ones((len(self.y_neop),), dtype=np.int32)  # np.ones((5,), dtype=int)

        # Only for train: compute the mean and std, and save them.
        if mode == 'train':
            # Compute the mean and std using only the train set (all the images in the train set)
            t = time.time()
            X_all = np.concatenate((self.X_neop, self.X_noneo), axis=0)
            self.preprocess(cf, X_all)
            print("   Time to compute mean and std: {0:.2f} seconds.".format(time.time() - t))
            # Save the mean and std
            np.save(data_path + '_X_' + mode + '_mean_std', np.array([self.rgb_mean, self.rgb_std], dtype=np.float32))
            print("   Mean and std saved to ", data_path + '_X_' + mode + '_mean_std.npy')

        else: # for validation or test
            print("   Reading mean and std from " + data_path2 + '_X_' + 'train' + '_mean_std.npy')
            tmp = np.load(data_path2 + '_X_' + 'train' + '_mean_std.npy')
            self.rgb_mean = tmp[0]
            self.rgb_std = tmp[1]


        # Statistic
        self.noneo_size = len(self.X_noneo)
        self.neop_size = len(self.X_neop)

        self.total_images = self.noneo_size + self.neop_size

        self.proportion_class_noneo = (len(self.X_noneo) * 100) / self.total_images  # it is the lowest
        # proportion_class_neop = (len(self.X_neop) * 100) / self.total_images

        self.noneo_batch_size = int(round((self.proportion_class_noneo * self.batch_size) / 100))

        self.neop_batch_size = self.batch_size - self.noneo_batch_size

        # Load training set
        print('\n   Information: ' + mode + ' set')
        print('   Total images: ' + str(self.total_images))
        print('   Batch size: ' + str(self.batch_size))

        print('   Noneo images: ' + str(self.noneo_size))
        print('   Noneo batch size: ' + str(self.noneo_batch_size))

        print('   Neop images: ' + str(self.neop_size))
        print('   Neop batch size: ' + str(self.neop_batch_size))


        if self.mode == 'train': # or  self.mode == 'validation':
            # ADDING IMAGES TO MAKE DIVISIBLE THE AMOUNT OF IMAGES NECESSARY TO
            # FEED EACH BATCH EVERY TIME
            times_batch_size = (self.total_images // self.batch_size)

            feed_noneo = (times_batch_size * self.noneo_batch_size)
            if (self.noneo_size < feed_noneo):
                missing = feed_noneo - self.noneo_size
                for _ in range(missing):
                    random_idx = randint(0, len(self.X_noneo)-1)
                    self.X_noneo       = np.append(self.X_noneo, self.X_noneo[random_idx])
                    self.y_noneo_class = np.append(self.y_noneo_class, self.y_noneo_class[random_idx])

                self.noneo_size = len(self.X_noneo)
                print('   ===> NEW amount of Noneo images: ' + str(self.noneo_size))

            feed_neop  = (times_batch_size * self.neop_batch_size)
            if (self.neop_size < feed_neop):
                missing = feed_neop - self.neop_size
                for _ in range(missing):
                    random_idx = randint(0, len(self.X_neop)-1)
                    self.X_neop       = np.append(self.X_neop, self.X_neop[random_idx])
                    self.y_neop_class = np.append(self.y_neop_class, self.y_neop_class[random_idx])

                self.neop_size = len(self.X_neop)
                print('   ===> NEW amount Neop images: ' + str(self.noneo_size))


        self.mix()

        if self.mode == 'train':
            self.da_stats = []  # it will store information to be used by data augmentation
            for _ in range(len(self.X_neop)):
                self.da_stats.append([])


    def mix(self):
        if self.mode == 'test' or self.mode == 'validation':
            self.X_global = np.concatenate((self.X_noneo, self.X_neop), axis=0)
            self.y_global = np.concatenate((self.y_noneo_class, self.y_neop_class), axis=0)
            if self.shuffle_dataset:
                shuffle(self.X_global, self.y_global)

        if self.mode == 'train':           
            if self.shuffle_dataset:
                shuffle(self.X_noneo, self.y_noneo_class)
                shuffle(self.X_neop, self.y_neop_class)

            # Keep this initialization inside of this if ;)
            self.X_global = np.array([])
            self.y_global = np.array([])

            for nFiles in range(self.total_images // self.batch_size):
                #print("nFiles: {}".format(nFiles))
                #print("self.total_images // self.batch_size : {}".format(self.total_images // self.batch_size))

                X_noneo_names =        self.X_noneo[nFiles * self.noneo_batch_size:(nFiles + 1) * self.noneo_batch_size]
                y_noneo_labels = self.y_noneo_class[nFiles * self.noneo_batch_size:(nFiles + 1) * self.noneo_batch_size]
                #print("\n")
                #print("len(X_noneo_names): {}".format(len(X_noneo_names)))
                #print("X_noneo_names: {}".format(X_noneo_names))
                #print("leng(y_noneo_labels): {}".format(len(y_noneo_labels)))
                #print("y_noneo_labels: {}".format(y_noneo_labels))

                X_neop_names =        self.X_neop[nFiles * self.neop_batch_size:(nFiles + 1) * self.neop_batch_size]
                y_neop_labels = self.y_neop_class[nFiles * self.neop_batch_size:(nFiles + 1) * self.neop_batch_size]

                #print("\n")
                #print("len(X_neop_names): {}".format(len(X_neop_names)))
                #print("X_neop_names: {}".format(X_neop_names))
                #print("len(y_neop_labels): {}".format(len(y_neop_labels)))
                #print("y_neop_labels: {}".format(y_neop_labels))

                X_tmp = np.concatenate((X_noneo_names, X_neop_names), axis=0)
                y_tmp = np.concatenate((y_noneo_labels, y_neop_labels), axis=0)


                self.X_global = np.concatenate((self.X_global, X_tmp), axis=0)
                self.y_global = np.concatenate((self.y_global, y_tmp), axis=0)

                #print("\n")
                #print("len(self.X_global): {}".format(len(self.X_global)))
                #print("self.X_global: {}".format(self.X_global))
                #print("len(self.y_global): {}".format(len(self.y_global)))
                #print("self.y_global: {}".format(self.y_global))
            # DO NOT SHUFFLE, BECAUSE IMAGES ARE READY TO BE TAKEN BY THE BATCH_SIZE


    def preprocess(self, cf, X_all):

        # Compute mean
        if self.featurewise_center:
            self.rgb_mean = compute_mean_std(self.dataset_images_path, X_all, self.resize_image, self.rescale, method='mean',
                                             mean=None)
            # Broadcast the shape
            broadcast_shape = [1, 1, 3]
            self.mean = np.reshape(self.rgb_mean, broadcast_shape)
            print('   Mean {}: {}'.format(self.mean.shape, self.rgb_mean, self.mean))
            #print("self.rgb_mean: {}".format(self.rgb_mean))

        # Compute std
        if self.featurewise_std_normalization:
            if not cf.norm_featurewise_center:
                self.rgb_mean = compute_mean_std(self.dataset_images_path, X_all, self.resize_image, self.rescale, method='mean',
                                                 mean=None)

            var = compute_mean_std(self.dataset_images_path, X_all, self.resize_image, self.rescale, method='var', mean=self.rgb_mean)
            self.rgb_std = np.sqrt(var)
            # Broadcast the shape
            broadcast_shape = [1, 1, 3]
            self.std = np.reshape(self.rgb_std, broadcast_shape)
            print('   Std {}: {}'.format(self.std.shape, self.rgb_std))
            #print("self.rgb_std: {}".format(self.rgb_std))


    def standardize(self, x):
        if self.imageNet:
            # assuming tf ordering
            # 'RGB'->'BGR'
            x = x[:, :, ::-1]
            # Zero-center by mean pixel
            x[:, :, 0] -= 103.939
            x[:, :, 1] -= 116.779
            x[:, :, 2] -= 123.68
            return x


        # Normalize
        if self.rescale:
            x *= self.rescale

        # Standardize
        if self.featurewise_center:
            if self.rgb_mean is not None:
                x -= self.rgb_mean
            else:
                warnings.warn('This Data_Generator specifies `featurewise_center`, but it hasn\'t'
                              'been fit on any training data')

        if self.featurewise_std_normalization:
            if self.rgb_std is not None:
                x /= (self.rgb_std + 1e-7)
            else:
                warnings.warn('This Data_Generator specifies `featurewise_std_normalization`, but it hasn\'t'
                              'been fit on any training data.')

        return x

    #######################################################
    #######################################################
    #######################################################
    def random_channel_shift(self, x, intensity, channel_axis=0):
        x = np.rollaxis(x, channel_axis, 0)
        min_x, max_x = np.min(x), np.max(x)
        channel_images = [np.clip(x_channel + np.random.uniform(-intensity, intensity), min_x, max_x)
                          for x_channel in x]
        x = np.stack(channel_images, axis=0)
        x = np.rollaxis(x, 0, channel_axis + 1)
        return x

    def transform_matrix_offset_center(self, matrix, x, y):
        o_x = float(x) / 2 + 0.5
        o_y = float(y) / 2 + 0.5
        offset_matrix = np.array([[1, 0, o_x], [0, 1, o_y], [0, 0, 1]])
        reset_matrix = np.array([[1, 0, -o_x], [0, 1, -o_y], [0, 0, 1]])
        transform_matrix = np.dot(np.dot(offset_matrix, matrix), reset_matrix)
        return transform_matrix

    def apply_transform(self, x,
                        transform_matrix,
                        channel_axis=0,
                        fill_mode='nearest',
                        cval=0.):
        """Apply the image transformation specified by a matrix.
        # Arguments
            x: 2D numpy array, single image.
            transform_matrix: Numpy array specifying the geometric transformation.
            channel_axis: Index of axis for channels in the input tensor.
            fill_mode: Points outside the boundaries of the input
                are filled according to the given mode
                (one of `{'constant', 'nearest', 'reflect', 'wrap'}`).
            cval: Value used for points outside the boundaries
                of the input if `mode='constant'`.
        # Returns
            The transformed version of the input.
        """
        x = np.rollaxis(x, channel_axis, 0)
        final_affine_matrix = transform_matrix[:2, :2]
        final_offset = transform_matrix[:2, 2]
        channel_images = [ndi.interpolation.affine_transform(
            x_channel,
            final_affine_matrix,
            final_offset,
            order=0,
            mode=fill_mode,
            cval=cval) for x_channel in x]
        x = np.stack(channel_images, axis=0)
        x = np.rollaxis(x, 0, channel_axis + 1)
        return x

    def flip_axis(self, x, axis):
        x = np.asarray(x).swapaxes(axis, 0)
        x = x[::-1, ...]
        x = x.swapaxes(0, axis)
        return x
        
        
    # Pad image
    def pad_image(self, x, pad_amount, mode='reflect', constant=0.):
        e = pad_amount
        shape = list(x.shape)
        shape[:2] += 2 * e
        if mode == 'constant':
            x_padded = np.ones(shape, dtype=np.float32) * constant
            x_padded[e:-e, e:-e] = x.copy()
        else:
            x_padded = np.zeros(shape, dtype=np.float32)
            x_padded[e:-e, e:-e] = x.copy()

        if mode == 'reflect':
            x_padded[:e, e:-e] = np.flipud(x[:e, :])  # left edge
            x_padded[-e:, e:-e] = np.flipud(x[-e:, :])  # right edge
            x_padded[e:-e, :e] = np.fliplr(x[:, :e])  # top edge
            x_padded[e:-e, -e:] = np.fliplr(x[:, -e:])  # bottom edge
            x_padded[:e, :e] = np.fliplr(np.flipud(x[:e, :e]))  # top-left corner
            x_padded[-e:, :e] = np.fliplr(np.flipud(x[-e:, :e]))  # top-right cor
            x_padded[:e, -e:] = np.fliplr(np.flipud(x[:e, -e:]))  # bot-left cor
            x_padded[-e:, -e:] = np.fliplr(np.flipud(x[-e:, -e:]))  # bot-right cor
        elif mode == 'zero' or mode == 'constant':
            pass
        elif mode == 'nearest':
            x_padded[:e, e:-e] = x[[0], :]  # left edge
            x_padded[-e:, e:-e] = x[[-1], :]  # right edge
            x_padded[e:-e, :e] = x[:, [0]]  # top edge
            x_padded[e:-e, -e:] = x[:, [-1]]  # bottom edge
            x_padded[:e, :e] = x[[0], [0]]  # top-left corner
            x_padded[-e:, :e] = x[[-1], [0]]  # top-right corner
            x_padded[:e, -e:] = x[[0], [-1]]  # bottom-left corner
            x_padded[-e:, -e:] = x[[-1], [-1]]  # bottom-right corner
        else:
            raise ValueError("Unsupported padding mode \"{}\"".format(mode))
        return x_padded


    # Define warp
    def gen_warp_field(self, shape, sigma=0.1, grid_size=3):
        # Initialize bspline transform
        args = shape + (sitk.sitkFloat32,)
        ref_image = sitk.Image(*args)
        tx = sitk.BSplineTransformInitializer(ref_image, [grid_size, grid_size])

        # Initialize shift in control points:
        # mesh size = number of control points - spline order
        p = sigma * np.random.randn(grid_size + 3, grid_size + 3, 2)

        # Anchor the edges of the image
        p[:, 0, :] = 0
        p[:, -1:, :] = 0
        p[0, :, :] = 0
        p[-1:, :, :] = 0

        # Set bspline transform parameters to the above shifts
        tx.SetParameters(p.flatten())

        # Compute deformation field
        displacement_filter = sitk.TransformToDisplacementFieldFilter()
        displacement_filter.SetReferenceImage(ref_image)
        displacement_field = displacement_filter.Execute(tx)

        return displacement_field
        
        
    # Apply warp
    def apply_warp(self, x, warp_field, fill_mode='reflect',
                   interpolator=sitk.sitkLinear,
                   fill_constant=0):
        # Expand deformation field (and later the image), padding for the largest
        # deformation
        warp_field_arr = sitk.GetArrayFromImage(warp_field)
        max_deformation = np.max(np.abs(warp_field_arr))
        pad = np.ceil(max_deformation).astype(np.int32)
        warp_field_padded_arr = self.pad_image(warp_field_arr, pad_amount=pad,
                                          mode='nearest')
        warp_field_padded = sitk.GetImageFromArray(warp_field_padded_arr,
                                                   isVector=True)

        # Warp x, one filter slice at a time
        x_warped = np.zeros(x.shape, dtype=np.float32)
        warp_filter = sitk.WarpImageFilter()
        warp_filter.SetInterpolator(interpolator)
        warp_filter.SetEdgePaddingValue(np.min(x).astype(np.double))
        for i, image in enumerate(x):
            image_padded = self.pad_image(image, pad_amount=pad, mode=fill_mode,
                                     constant=fill_constant).T
            image_f = sitk.GetImageFromArray(image_padded)
            image_f_warped = warp_filter.Execute(image_f, warp_field_padded)
            image_warped = sitk.GetArrayFromImage(image_f_warped)
            x_warped[i] = image_warped[pad:-pad, pad:-pad].T

        return x_warped

    def random_transform(self, x):
        # x is a single image, so it doesn't have image number at index 0
        img_row_index = 0  # self.row_index - 1
        img_col_index = 1  # self.col_index - 1
        img_channel_index = 2  # self.channel_index - 1

        # use composition of homographies to generate final transform that
        # needs to be applied
        need_transform = False

        # Rotation
        if self.rotation_range:
            theta = np.pi / 180 * np.random.uniform(-self.rotation_range, self.rotation_range)
            need_transform = True
        else:
            theta = 0

        # Shift in height
        if self.height_shift_range:
            tx = np.random.uniform(-self.height_shift_range, self.height_shift_range) * x.shape[img_row_index]
            need_transform = True
        else:
            tx = 0

        # Shift in width
        if self.width_shift_range:
            ty = np.random.uniform(-self.width_shift_range, self.width_shift_range) * x.shape[img_col_index]
            need_transform = True
        else:
            ty = 0

        # Shear
        if self.shear_range:
            shear = np.random.uniform(-self.shear_range, self.shear_range)
            need_transform = True
        else:
            shear = 0

        # Zoom
        if self.zoom_range[0] == 1 and self.zoom_range[1] == 1:
            zx, zy = 1, 1
        else:
            zx, zy = np.random.uniform(self.zoom_range[0], self.zoom_range[1], 2)
            need_transform = True

        if need_transform:
            rotation_matrix = np.array([[np.cos(theta), -np.sin(theta), 0],
                                        [np.sin(theta), np.cos(theta), 0],
                                        [0, 0, 1]])

            translation_matrix = np.array([[1, 0, tx],
                                           [0, 1, ty],
                                           [0, 0, 1]])

            shear_matrix = np.array([[1, -np.sin(shear), 0],
                                     [0, np.cos(shear), 0],
                                     [0, 0, 1]])

            zoom_matrix = np.array([[zx, 0, 0],
                                    [0, zy, 0],
                                    [0, 0, 1]])

            transform_matrix = np.dot(np.dot(np.dot(rotation_matrix,
                                                    translation_matrix),
                                             shear_matrix), zoom_matrix)

            h, w = x.shape[img_row_index], x.shape[img_col_index]
            transform_matrix = self.transform_matrix_offset_center(transform_matrix,
                                                              h, w)
            x = self.apply_transform(x, transform_matrix, img_channel_index, fill_mode=self.fill_mode, cval=self.cval)

        if self.channel_shift_range != 0:
            x = self.random_channel_shift(x, self.channel_shift_range, img_channel_index)

        if self.horizontal_flip:
            if np.random.random() < 0.5:
                x = self.flip_axis(x, img_col_index)

        if self.vertical_flip:
            if np.random.random() < 0.5:
                x = self.flip_axis(x, img_row_index)

        #if self.spline_warp:
        #    warp_field = self.gen_warp_field(shape=x.shape[-2:],
        #                                sigma=self.warp_sigma,
        #                                grid_size=self.warp_grid_size)
        #    x = self.apply_warp(x, warp_field,
        #                   interpolator=sitk.sitkLinear,
        #                   fill_mode=self.fill_mode, fill_constant=self.cval)


        if self.crop_size is not None:
            x = self.crop(x, 'center')
        # Crop
        # TODO: tf compatible???
        #crop = list(self.crop_size) if self.crop_size else None
        #if crop:
        #    #print ('X before: ' + str(x.shape))
        #    # print ('Y before: ' + str(y.shape))
        #    #print ('Crop_size: ' + str(self.crop_size))
        #    h, w = x.shape[img_row_index], x.shape[img_col_index]

        #    # Padd image if it is smaller than the crop size
        #    pad_h1, pad_h2, pad_w1, pad_w2 = 0, 0, 0, 0
        #    if h < crop[0]:
        #        total_pad = crop[0] - h
        #        pad_h1 = math.ceil(total_pad / 2)
        #        pad_h2 = total_pad - pad_h1
        #    if w < crop[1]:
        #        total_pad = crop[1] - w
        #        pad_w1 = math.ceil(total_pad / 2)
        #        pad_w2 = total_pad - pad_w1
        #    if h < crop[0] or w < crop[1]:
        #        #print ("pad_h1: {}".format(pad_h1))
        #        #print ("pad_h2: {}".format(pad_h2))
        #        #print ("pad_w1: {}".format(pad_w1))
        #        #print ("pad_w2: {}".format(pad_w2))
        #        x = np.lib.pad(x, ((pad_h1, pad_h2), (pad_w1, pad_w2), (0, 0)), 'constant')

        #        h, w = x.shape[img_row_index], x.shape[img_col_index]
        #        #print ('=====>>>> New size X: ' + str(x.shape))
        #        # print ('New size Y: ' + str(y.shape))
        #        # exit()

        #    if crop[0] < h:
        #        top = np.random.randint(h - crop[0])
        #    else:
        #        #print('Data augmentation: Crop height >= image size')
        #        top, crop[0] = 0, h
        #    if crop[1] < w:
        #        left = np.random.randint(w - crop[1])
        #    else:
        #        # print('Data augmentation: Crop width >= image size')
        #        left, crop[1] = 0, w

        #    # self.dim_ordering = 'tf'
        #    x = x[..., top:top + crop[0], left:left + crop[1], :]

            #print ('>>>>>>>>>>>>>>X after: ' + str(x.shape))
            # print ('Y after: ' + str(y.shape))

        # TODO: save to dir images transformed.

        return x

    #######################################################
    #######################################################
    #######################################################

    def crop(self, x, mode=None):
        crop = list(self.crop_size) if self.crop_size else None
        img_row_index = 0  # self.row_index - 1
        img_col_index = 1  # self.col_index - 1
        img_channel_index = 2  # self.channel_index - 1
        #print ('X before: ' + str(x.shape))
        # print ('Y before: ' + str(y.shape))
        #print ('Crop_size: ' + str(self.crop_size))
        h, w = x.shape[img_row_index], x.shape[img_col_index]
    
        # Padd image if it is smaller than the crop size
        pad_h1, pad_h2, pad_w1, pad_w2 = 0, 0, 0, 0
        if h < crop[0]:
            total_pad = crop[0] - h
            pad_h1 = math.ceil(total_pad / 2)
            pad_h2 = total_pad - pad_h1
        if w < crop[1]:
            total_pad = crop[1] - w
            pad_w1 = math.ceil(total_pad / 2)
            pad_w2 = total_pad - pad_w1
        if h < crop[0] or w < crop[1]:
            #print ("pad_h1: {}".format(pad_h1))
            #print ("pad_h2: {}".format(pad_h2))
            #print ("pad_w1: {}".format(pad_w1))
            #print ("pad_w2: {}".format(pad_w2))
            x = np.lib.pad(x, ((pad_h1, pad_h2), (pad_w1, pad_w2), (0, 0)), 'constant')
        
            h, w = x.shape[img_row_index], x.shape[img_col_index]
            #print ('=====>>>> New size X: ' + str(x.shape))
            # print ('New size Y: ' + str(y.shape))
            # exit()
        
        if mode == None:
            if crop[0] < h:
                top = np.random.randint(h - crop[0])
            else:
                #print('Data augmentation: Crop height >= image size')
                top, crop[0] = 0, h
            if crop[1] < w:
                left = np.random.randint(w - crop[1])
            else:
                # print('Data augmentation: Crop width >= image size')
                left, crop[1] = 0, w
        
            # self.dim_ordering = 'tf'
            x = x[..., top:top + crop[0], left:left + crop[1], :]
        
            #print ('>>>>>>>>>>>>>>X after: ' + str(x.shape))
            # print ('Y after: ' + str(y.shape))
        elif mode == 'center':
            center_h = (h // 2)
            center_w = (w // 2)
            top = center_h - (crop[0]//2)
            left = center_w - (crop[1]//2)
    
            #print("center_h: ", center_h)
            #print("center_w: ", center_w)
            #print("crop[0]//2: ", crop[0]//2)
            #print("crop[1]//2: ", crop[1]//2)
            #print("top: ",top)
            #print("left: ",left)
            #print(">>>> X before: " + str(x.shape))
    
            x = x[..., top:top + crop[0], left:left + crop[1], :]
        
    
            #print(">>>> X after: " + str(x.shape))
    
    
        # TODO: save to dir images transformed.
        
        return x




    ##############################################
    def data_augmentation(self, x, idx):
        """ x: is a single image
            idx: is an index for self.da_stats
        """
        # Only it is possible to apply data augmentation in train set
        if self.apply_augmentation and self.mode == 'train':

            return self.random_transform(x)

            #if self.y_global[idx] == 0:
            #    return self.random_transform(x)
            #else:
            #    return x

            # if len(self.da_stats[idx]) == 4:
            #     self.da_stats[idx] = []
            #
            # flag = True
            # delta = 0
            #
            # while flag:
            #     delta = randint(0, 3)
            #     if delta not in self.da_stats[idx]:
            #         self.da_stats[idx].append(delta)
            #         flag = False
            #
            #
            # if delta == 0:
            #     return x
            # elif delta == 1:
            #     return np.fliplr(x)
            # elif delta == 2:
            #     return np.flipud(x)
            # elif delta == 3:
            #     return np.flipud(np.fliplr(x))

        else:
            return x


    # strategy 1: keep unbalanced each batch as the dataset.
    def generate(self):

        while True:


            for nFiles in range(self.total_images // self.batch_size):

                #print("\n")
                #print("MODE: {}".format(self.mode))

                #if self.mode == 'train' or self.mode =='validation': 
                #    print("nFiles: {}".format(nFiles))
                #    print("self.total_images: {}".format(self.total_images))
                #    print("self.batch_size: {}".format(self.batch_size))
                #    print("\n")
    
                #    print("self.total_images // self.batch_size : {}".format(self.total_images // self.batch_size))
                #    print("len(self.X_global): {}".format(len(self.X_global)))

                self.batch_fnames = self.X_global[nFiles * self.batch_size:(nFiles + 1) * self.batch_size]
                self.batch_labels = self.y_global[nFiles * self.batch_size:(nFiles + 1) * self.batch_size]

                #if self.mode == 'train' or self.mode =='validation':
                #    print("\n")
                #    print("len(self.batch_fnames): {}".format(len(self.batch_fnames)))
                #    print("self.batch_fnames: {}".format(self.batch_fnames))
                #    print("len(self.batch_labels): {}".format(len(self.batch_labels)))
                #    print("self.batch_labels: {}".format(self.batch_labels))


                #print ("\n len(batch_fnames) = ", len(batch_fnames))
                #print ("\n self.batch_size = ", self.batch_size)

                assert len(self.batch_fnames) == self.batch_size

                #if len(batch_fnames) != self.batch_size:
                #    print("\n %%%%%%%%%")
                #    continue

                
                #if len(batch_fnames) != self.batch_size:
                #    print("\n >>>>>>>> batch_fnames = ", batch_fnames)
                #    print("\n >>>>>>>> batch_labels = ", batch_labels)


                #print(">>>>>>>> batch_fnames = ", batch_fnames)
                #print(">>>>>>>> batch_labels = ", batch_labels)
                img_batch = []
                lab_batch = []

                if self.shuffle_batch:
                    shuffle(self.batch_fnames, self.batch_labels)

                fnames_list=[]
                
                # Create the batch_x and batch_y
                for idx, image_name in enumerate(self.batch_fnames):
                    #print("\n Reading images")
                    # image = imread(os.path.join(self.dataset_images_path, image_name))  # Build batch of image data
                    #
                    # if self.resize_image is not None:
                    #     image = skimage.transform.resize(image, self.resize_image, order=1, preserve_range=True)
                    #     #print("resized")
                    
                    #print("Reading image: {}",format(os.path.join(self.dataset_images_path, image_name)))
                    #sys.stdout.flush()

                    image = load_img(os.path.join(self.dataset_images_path, image_name), resize=self.resize_image)
                    fnames_list.append(image_name)
                    image = np.asarray(image, dtype='float32')   # image = image.astype('float32')
                    image = self.standardize(image)
                    if self.mode == 'train':
                        image = self.data_augmentation(image, idx)
                    else:
                        if self.crop_size is not None:
                            image = self.crop(image, 'center')


                    #image = skimage.transform.resize(image, self.resize_image, order=1, preserve_range=True)

                    # Add images to batches
                    img_batch.append(image)
                    # Build batch of label data, reshape and add to batch
                    lab_batch.append(to_categorical(self.batch_labels[idx], self.n_classes).reshape(self.n_classes))
                    #print("SHAPE img_batch: {} , lab_batch: {}: ".format( np.array(img_batch).shape, np.array(lab_batch).shape )) 
                

                #print("\n >> lab_batch = ", np.array(lab_batch)) 
                #if self.mode == 'validation':
                #    sys.stdout.flush()
                #    print(fnames_list) 
                #    sys.stdout.flush()
                yield (np.array(img_batch), np.array(lab_batch))

